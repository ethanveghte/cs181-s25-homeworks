{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CS 1810 Homework 4**\n",
    "---\n",
    "To account for potential version issues, try the following in your terminal:\n",
    "\n",
    "1. Create a new environment with `python3 -m venv venv`\n",
    "2. Activate that environment with `source venv/bin/activate`\n",
    "3. Make sure the interpreter in the top right corner of your VSCode (or whatever you use to run your code is venv).\n",
    "4. If you get a \"install kernel\" message, press it.\n",
    "5. Run `pip install -r requirements.txt`\n",
    "6. Run the remainder of this notebook.\n",
    "\n",
    "Note that this is not necessary but can help prevent any issues due to package versions.\n",
    "\n",
    "**The following notebook is meant to help you work through Problem 2 on Homework 4. You are by no means required to use it, nor are you required to fill out/use any of the boilerplate code/functions. You are welcome to implement the functions however you wish.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import heatmap\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "\n",
    "small_dataset = np.load(\"data/small_dataset.npy\")\n",
    "small_labels = np.load(\"data/small_dataset_labels.npy\").astype(int)\n",
    "large_dataset = np.load(\"data/large_dataset.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans(object):\n",
    "    # K is the K in KMeans\n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "\n",
    "    # Some helper functions may go here:\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Run the k-Means algorithm for exactly 10 iterations.\n",
    "\n",
    "        :param X: a (N x 784) array since the dimension of each image is 28x28\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "        \n",
    "    def plot_verify_objective(self):\n",
    "        \"\"\"\n",
    "        This should plot the objective as a function of iteration and verify that it never increases.\n",
    "\n",
    "        This assumes that fit() has already been called.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def get_mean_images(self):\n",
    "        \"\"\" \n",
    "        This should return the arrays for K images. Each image should represent the mean of each of the fitted clusters.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def get_cluster_sizes(self):\n",
    "        # YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMeansClassifier = KMeans(K=10)\n",
    "KMeansClassifier.fit(large_dataset)\n",
    "KMeansClassifier.plot_verify_objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for plots in part 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_image_plot(data, standardized = False, filename=None):\n",
    "    niters = 3\n",
    "    K = 10\n",
    "    allmeans = np.zeros((K, niters, 784))\n",
    "    for i in range(niters):\n",
    "        KMeansClassifier = KMeans(K=K)\n",
    "        KMeansClassifier.fit(data)\n",
    "        allmeans[:,i] = KMeansClassifier.get_mean_images()\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.suptitle('Class mean images across random restarts' + (' (standardized data)' if standardized else ''), fontsize=16)\n",
    "    for k in range(K):\n",
    "        for i in range(niters):\n",
    "            ax = fig.add_subplot(K, niters, 1+niters*k+i)\n",
    "            plt.setp(ax.get_xticklabels(), visible=False)\n",
    "            plt.setp(ax.get_yticklabels(), visible=False)\n",
    "            ax.tick_params(axis='both', which='both', length=0)\n",
    "            if k == 0: plt.title('Iter '+str(i))\n",
    "            if i == 0: ax.set_ylabel('Class '+str(k), rotation=90)\n",
    "            plt.imshow(allmeans[k,i].reshape(28,28), cmap='Greys_r')\n",
    "    if filename:\n",
    "        plt.savefig(f'img_output/{filename}') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mean_image_plot(large_dataset, filename='p2.2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this\n",
    "large_dataset_std = None \n",
    "\n",
    "# YOUR CODE HERE\n",
    "pass\n",
    "\n",
    "make_mean_image_plot(large_dataset_std, standardized = True, filename='p2.3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAC: Part 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAC(object):\n",
    "    def __init__(self, linkage):\n",
    "        self.linkage = linkage\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    # Some helper functions can go here:\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    # Return assignments when there were K clusters\n",
    "    def get_k_clusters(self, K):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    # Get mean images when using K clusters\n",
    "    def get_mean_images(self, K):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    # Get cluster sizes to compare min and max linkage\n",
    "    def get_cluster_sizes(self, K):\n",
    "        # YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: This takes ~6 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINKAGES = [ 'max', 'min', 'centroid' ]\n",
    "n_clusters = 10\n",
    "cluster_sizes = []\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.suptitle(\"HAC mean images with max, min, and centroid linkagess\")\n",
    "for l_idx, l in enumerate(LINKAGES):\n",
    "    # Fit HAC\n",
    "    hac = HAC(l)\n",
    "    hac.fit(small_dataset)\n",
    "    mean_images = hac.get_mean_images(n_clusters)\n",
    "    cluster_sizes.append(hac.get_cluster_sizes(n_clusters)) # used in Part 8, append here to avoid re-fitting\n",
    "    # Make plot\n",
    "    for m_idx in range(mean_images.shape[0]):\n",
    "        m = mean_images[m_idx]\n",
    "        ax = fig.add_subplot(n_clusters, len(LINKAGES), l_idx + m_idx*len(LINKAGES) + 1)\n",
    "        plt.setp(ax.get_xticklabels(), visible=False)\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "        ax.tick_params(axis='both', which='both', length=0)\n",
    "        if m_idx == 0: plt.title(l)\n",
    "        if l_idx == 0: ax.set_ylabel('Class '+str(m_idx), rotation=90)\n",
    "        plt.imshow(m.reshape(28,28), cmap='Greys_r')\n",
    "    print(\"Done:\", l)\n",
    "plt.savefig('img_output/p2.4.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAC graphs\n",
    "def plot_cluster_sizes(n_clusters, cluster_sizes, filename=None):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    fig.suptitle(\"HAC Cluster Sizes\")\n",
    "    ax1.set_ylabel('number of images in cluster')\n",
    "    cluster_idxs = [i for i in range(n_clusters)]\n",
    "\n",
    "    def plot_sizes_per_linkage(ax, sizes, linkage):\n",
    "        ax.bar(cluster_idxs, sizes)\n",
    "        ax.set_title(f'{linkage} Linkage')\n",
    "        ax.set_xlabel('cluster index')\n",
    "        ax.set_ylim(0, 300)\n",
    "\n",
    "    plot_sizes_per_linkage(ax1, cluster_sizes[0], 'Max')\n",
    "    plot_sizes_per_linkage(ax2, cluster_sizes[1], 'Min')\n",
    "    plot_sizes_per_linkage(ax3, cluster_sizes[2], 'Centroid')\n",
    "    if filename:\n",
    "        plt.savefig(f'img_output/{filename}') \n",
    "    plt.show()\n",
    "plot_cluster_sizes(n_clusters, cluster_sizes, filename='p2.5a.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means graphs\n",
    "def plot_cluster_sizes(n_clusters, cluster_sizes, filename=None):\n",
    "    fig, (ax) = plt.subplots(1, 1)\n",
    "    fig.suptitle(\"K-means Cluster Sizes\")\n",
    "    ax.set_ylabel('number of images in cluster')\n",
    "    cluster_idxs = [i for i in range(n_clusters)]\n",
    "\n",
    "    def plot_sizes_per_linkage(ax, sizes, k):\n",
    "        ax.bar(cluster_idxs, sizes)\n",
    "        ax.set_title(f'K = {k}')\n",
    "        ax.set_xlabel('cluster index')\n",
    "        ax.set_ylim(0, 1000)\n",
    "\n",
    "    plot_sizes_per_linkage(ax, cluster_sizes, str(n_clusters))\n",
    "    if filename:\n",
    "        plt.savefig(f'img_output/{filename}') \n",
    "    plt.show()\n",
    "\n",
    "plot_cluster_sizes(KMeansClassifier.K, KMeansClassifier.get_cluster_sizes(), filename='p2.5b.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
